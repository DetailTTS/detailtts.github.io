<!DOCTYPE html>
<html lang="en-US">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">


  <title>DetailTTS: Learning Residual Detail Information for Zero-shot Text-to-speech</title>
  <meta name="generator" content="Jekyll v3.9.0">
  <meta property="og:title" content="title">
  <meta property="og:locale" content="en_US">
  <meta name="twitter:card" content="summary">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#66ccff">
  <link rel="stylesheet" href="style.css">
  <style>
    p {
      text-indent: 2em;
    }

    .method {
      display: inline-block;
      font-weight: bold;
    }

    .explanation {
      display: inline-block;
    }

    .centered-table {
      width: 50%;
      border-collapse: collapse;
      box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2);
      margin-top: 20px;
      margin-bottom: 20px;
      background: white;
      margin-left: auto;
      margin-right: auto;
    }

    .centered-table th,
    .centered-table td {
      border: 1px solid #ddd;
      text-align: center;
      padding: 10px;
      font-size: 0.85em;
    }

    .centered-table th {
      background-color: #f2f2f2;
      color: #333;
    }

    .centered-table caption {
      caption-side: top;
      font-weight: bold;
      margin-bottom: 10px;
      text-align: center;
      font-size: 1.1em;
    }

    .centered-table tr:hover {
      background-color: #f5f5f5;
    }

    .model-list {
      list-style-type: none;
      margin: 0;
      padding: 0;
    }

    .model-item {
      display: flex;
      align-items: center;
      margin-bottom: 10px;
    }

    .model-name {
      font-weight: bold;
      margin-right: 5px;
      flex: 0 0 auto;
    }

    .model-description {
      flex-grow: 1;
    }
  </style>
</head>

<body data-new-gr-c-s-check-loaded="14.1001.0" data-gr-ext-installed="">
  <section class="page-header">
  </section>

  <section class="main-content">
    <h1 id="">
      <center>DetailTTS: Learning Residual Detail Information <br>for Zero-shot Text-to-speech</center>
    </h1>

    <center>
      <font size="4">(Submitted on ICASSP 2025)</font>
    </center>

    <center><b>
        <font size="4">Authors</font>
      </b>: <i>
        <font size="4">Cong Wang<sup>1</sup>, Yichen Han<sup>1</sup>, Yizhong Geng<sup>1</sup>, Yingming
          Gao<sup>1</sup>,<br> Fengping Wang<sup>1</sup>, Bingsong Bai<sup>1</sup>, Qifei Li<sup>1</sup>, Jinlong
          Xue<sup>1</sup>, Yayue Deng<sup>1</sup>, Zhengqi Wen<sup>2</sup>, Ya Li<sup>1,*</sup></font>
      </i></center>
    <center>
      <font size="4"><sup>1</sup>Beijing University of Posts and Telecommunications, Beijing, China</font>
    </center>
    <center>
      <font size="4"><sup>2</sup>Tsinghua University, Beijing, China</font>
    </center>

    <br>
    <center>
      <a href="https://github.com/adelacvg/ttts">Source Code</a> &
      <a href="https://huggingface.co/adelacvg/TTTS_v4">Pre-trained Model</a> &
      <a href="https://colab.research.google.com/github/adelacvg/ttts/blob/v4/demo.ipynb">Colab Demo</a>
    </center>
    <center><i>
        <font size="2">(The code and models for the paper are being prepared.)</font>
      </i></center>

    <h2 id="abstract">1. Abstract<a name="abstract"></a></h2>
    <p>Traditional text-to-speech (TTS) systems often face challenges in aligning text and speech, leading to the
      omission of critical linguistic and acoustic details. This misalignment creates an information gap, which existing
      methods attempt to address by incorporating additional inputs, but these often introduce data inconsistencies and
      increase complexity. To address these issues, we propose <b>DetailTTS</b>, a zero-shot TTS system based on
      a conditional variational autoencoder. It incorporates two key components: the Prior Detail Module and the
      Duration Detail Module, which capture residual detail information missed during alignment. These modules
      effectively enhance the model’s ability to retain fine-grained details, significantly improving speech quality
      while simplifying the model by obviating the need for additional inputs. Experiments on the <a
        href="https://huggingface.co/datasets/Wenetspeech4TTS/WenetSpeech4TTS">WenetSpeech4TTS dataset</a> show that
      DetailTTS outperforms traditional TTS systems in both <b>naturalness</b> and <b>speaker similarity</b>, even in
      zero-shot scenarios.</p>

    <h2 id="Model Architecture">2. Model Architecture<a name="Model Architecture"></a></h2>
    <p>
      <center>
        <img src="./img/overview.png" width="80%">
      </center>
      <br>
      <caption>
        <font size="2">Fig. 1. The overall framework of DetailTTS, incorporating two key detail encoding modules: the
          Prior
          Detail Module and the Duration Detail Module. These modules learn to capture residual detail information
          during
          training, allowing them to provide this information even during inference with only text input, thereby
          improving the quality of the synthesized speech.</font>
      </caption>
      <center><img src="./img/duration.png" width="60%"></center>
      <br>
      <caption>
        <font size="2">Fig. 2. The duration detail module enhances the duration predictor by learning residual detail
          information during training. This allows the module to provide refined duration information even during
          inference with only text input, leading to more accurate and natural speech synthesis.</font>
      </caption>
      </center>
    </p>


    <h2>3. Zero-Shot TTS Samples <a name="Comparison"></a></h2>
    <h3>Seen Speakers </h3>
    <table style="max-width:100%;table-layout: fixed;">
      <tbody id="tbody_seen">
      </tbody>
    </table>
    <h3>Unseen Speakers</h3>
    <table style="max-width:100%;table-layout: fixed;">
      <tbody id="tbody_unseen">
      </tbody>
    </table>

    <h2 id="Experiments & Results">4. t-SNE<a name="Experiments & Results"></a></h2>
    <p>
      <center><img src="./img/t-SNE.png" width="40%"></center>
    </p>
    <p>We randomly selecte 15 speakers from the test dataset and conducted t-SNE visualization of the speaker embeddings
      for their synthesized and real speech. The speaker embeddings of synthesized speech and ground truth from the same
      speaker are closely clustered together, further demonstrating the superiority of our method in terms of speaker
      similarity.</p>



</html>

<script type="" text/javascript>
function seen_spk() {
  let scenes = [
    ["text1","seen1","应该给千千万万还在路上的创业者致意。(We should pay tribute to the millions of entrepreneurs who are still on their journey.)"],
    ["text2","seen1","准确点说，小森林是一部美食类电影食物佳肴，贯穿了柿子的寒暑交替四十三餐。(To be precise, 'Little Forest' is a gourmet movie that features forty-three meals, showcasing the seasonal changes of persimmons.)"],
    ["text3","seen2","要大力开展全省网吧专项整治工作，加强网络文化内容的整治，深入开展低俗音像制品清查行动。(It is necessary to vigorously carry out special rectification work on internet cafes across the province, strengthen the regulation of online cultural content, and thoroughly conduct a cleanup operation of vulgar audio-visual products.)"],
    ["text4","seen2","因为这是我们法律存在的前提。(Because this is the premise for the existence of our law.)"],
    ["text5","seen3","书记旗县市长乡镇苏木长企事业负责人以及国营农牧场的老兵团们，像赶庙会似的你挤我扛，口里说着，手里记着。(Secretaries, county and town mayors, township and sumu leaders, heads of enterprises and institutions, as well as veteran groups from state-owned farms and pastures, jostled like they were attending a temple fair, talking and taking notes.)"],
    ["text6","seen3","哎，不是有一句话这样说嘛，你永远不知道明天和意外哪个先来。(Alas, isn't there a saying that you never know whether tomorrow or an accident will come first?)"],
    ["text7","seen4","湿热天最麻烦的还属家中的煤气，早上起来，连拌果酱的木铲也发霉了。(On humid and hot days, the biggest nuisance is the gas at home; even the wooden spatula for stirring jam gets moldy.)"],
    ["text8","seen4","这时，朱警官等人才发现小男孩腿脚也异常，根本走不了路。(At this moment, Officer Zhu and others discovered that the little boy's legs were abnormal, and he couldn't walk at all.)"]

  ];
  let models = ["VALL-E", "NaturalSpeech2", "DetailTTS(Ours)"];
  let models_path = ["VALL-E", "NaturalSpeech2", "DetailTTS"];
  let data = `
      <colgroup>
        <col style="width: 5%;"> <!-- Sequence number column -->
        <col style="width: 10%;"> <!-- Reference speaker column -->
        <col style="width: 15%;"> <!-- Text column -->
  `;
  
  // Dynamically adding cols for each model
  models.forEach(function() {
    data += '<col style="width: 12.5%;">'; // Adjust the width as necessary
  });
  
  data += `</colgroup>
      <tr>
        <th><strong>No.</strong></th>
        <th style=""><strong>Reference Speaker</strong></th>
        <th style=""><strong>Text</strong></th>
  `;
  
  models.forEach(function(model) {
    data += '<th style=""><strong>' + model + '</strong></th>';
  });
  
  data += '</tr>';
  
  scenes.forEach(function(scene, index) {
    let file = scene[0];
    let spk = scene[1];
    let text = scene[2];
    let scene_data = "";
  
    scene_data += '<tr>';
    scene_data += '<td style="text-align: center;">' + (index + 1) + '</td>';
    scene_data += '<td style=""><audio controls="" style="width: 100%;" controls src="' + './raw/demos/Ref/' + spk + '_spk.wav' + '"></audio></td>';
    scene_data += '<td style=" font-size: 14px">' + text + '</td>';
    models_path.forEach(function(model) {
      scene_data += '<td style="text-align: center;"><audio style="width: 100%;" controls src="' + './raw/demos/' + model + '/' + spk+'_'+file + '.wav' + '"></audio></td>';
    });
    scene_data += '</tr>';
    data += scene_data;
  });
  
  
  return data;
}

function unseen_spk() {
  let scenes = [
    ["text1","unseen1","他一度梦想参军，但是因没身份而作罢，整日在村内瞎晃。(He once dreamed of joining the army, but gave up due to lack of identification, and wandered aimlessly in the village all day.)"],
    ["text2","unseen2","哎，不是有一句话这样说嘛，你永远不知道明天和意外哪个先来。(Alas, isn't there a saying that you never know whether tomorrow or an accident will come first?)"],
    ["text3","unseen2","当时有点感动还是什么？(Was it a bit touching or something at that time?)"],
    ["text4","unseen3","这些飞机仍然由位于华盛顿州埃弗里特的工厂生产。(These planes are still produced by the factory located in Everett, Washington State.)"],
    ["text5","unseen3","派大军前去争抢，赫赫查拉二话不说，喊出了巴顿的名字，结果手套开始传递给斯科特半路遭到灭霸拦截，真正的杀神从天而降。(A large army was sent to compete, Hehe Chala without hesitation called out Barton's name, resulting in the gauntlet being passed to Scott halfway, only to be intercepted by Thanos, as the true god of death descended from the heavens.)"],
    ["text6","unseen4","而中国却只是将其作为红旗反导系统下的一个补充而已。(And China merely considers it a supplement under the HQ anti-missile system.)"],
    ["text7","unseen5","这一段戏同样也表达了亚瑟说的，我原本以为我的人生是一出悲剧，但其实它是一出戏剧。(This part of the play also expressed what Arthur said, 'I used to think my life was a tragedy, but actually, it's a comedy.')"],
    ["text8","unseen5","常常暴跳如雷，红着眼睛用力攥着洛洛的手，把洛洛的手攥得生疼也不撒手。洛洛吓坏了，她很害怕，那个平日里对她那么好的男友为什么会变得这么可怕？(Often flying into a rage, his eyes red, he would grip Lolo's hand tightly, causing her pain without letting go. Lolo was terrified. She wondered why her boyfriend, who was so good to her on normal days, could become so frightening.)"],
  ];
  let models = ["VALL-E", "NaturalSpeech2", "DetailTTS(Ours)"];
  let models_path = ["VALL-E", "NaturalSpeech2", "DetailTTS"];
  let data = `
      <colgroup>
        <col style="width: 5%;"> <!-- Sequence number column -->
        <col style="width: 10%;"> <!-- Reference speaker column -->
        <col style="width: 20%;"> <!-- Text column -->
  `;
  

  models.forEach(function() {
    data += '<col style="width: 10%;">';
  });
  
  data += `</colgroup>
      <tr>
        <th><strong>No.</strong></th>
        <th style=""><strong>Reference Speaker</strong></th>
        <th style=""><strong>Text</strong></th>
  `;
  
  models.forEach(function(model) {
    data += '<th style=""><strong>' + model + '</strong></th>';
  });
  
  data += '</tr>';
  
  scenes.forEach(function(scene, index) {
    let file = scene[0];
    let spk = scene[1];
    let text = scene[2];
    let scene_data = "";
  
    scene_data += '<tr>';
    scene_data += '<td style="text-align: center;">' + (index + 1) + '</td>';
    scene_data += '<td style=""><audio controls="" style="width: 100%;" controls src="' + './raw/demos/Ref/' + spk + '_spk.wav' + '"></audio></td>';
    scene_data += '<td style=" font-size: 14px">' + text + '</td>';
    models_path.forEach(function(model) {
      scene_data += '<td style="text-align: center;"><audio style="width: 100%;" controls src="' + './raw/demos/' + model + '/' + spk+'_'+file + '.wav' + '"></audio></td>';
    });
    scene_data += '</tr>';
    data += scene_data;
  });
  
  return data;
}


window.onload = function() {
  document.getElementById('tbody_seen').innerHTML = seen_spk();
  document.getElementById('tbody_unseen').innerHTML = unseen_spk()
}


</script>